import numpy as np
from tensorflow.keras.models import load_model
import joblib
import os

# âœ… ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ëŠ” "1ë²ˆë§Œ" ë¡œë”©
model_dir = os.path.abspath(os.path.join("user", "model"))
fall_model = os.path.join(model_dir, "fall_model.keras")
scaler_model = os.path.join(model_dir, "scaler.pkl")

model = load_model(fall_model)
scaler = joblib.load(scaler_model)

def predict_fall(single_data):
    """í•˜ë‚˜ì˜ ìƒ˜í”Œ(new_data) ì˜ˆì¸¡í•˜ê¸°"""
    single_data_scaled = scaler.transform(single_data.reshape(1, -1))
    prediction = model.predict(single_data_scaled, verbose=0)
    fall_probability = prediction[0][0]
    return fall_probability

def batch_predict_fall(batch_data):
    """ì—¬ëŸ¬ ê°œ ìƒ˜í”Œ(batch_data)ì„ í•œêº¼ë²ˆì— ì˜ˆì¸¡í•˜ê¸°"""
    batch_data_scaled = scaler.transform(batch_data)  # batch_dataëŠ” (N, 16) í˜•íƒœ
    predictions = model.predict(batch_data_scaled, verbose=0)
    fall_probabilities = predictions.flatten()  # (N,) í˜•íƒœë¡œ ë³€í™˜
    return fall_probabilities

"""
if __name__ == "__main__":
    # âœ… ì—¬ê¸°ì„œëŠ” new_dataë§Œ ì¤€ë¹„í•˜ê³  í•¨ìˆ˜ í˜¸ì¶œ
    new_data = np.array([0.43, 0.62, 1, 1, 0.53, 0.62, 1, 1, 0.46, 0.82, 0.67, 0, 0.51, 0.75, 0.66, 0])
    
    fall_probability = predict_fall(new_data)

    print(f"ë‚™ìƒ í™•ë¥ : {fall_probability:.4f}")

    if fall_probability >= 0.5:
        print("ğŸš¨ ë‚™ìƒ ê°ì§€!")
    else:
        print("âœ… ì •ìƒ ìƒíƒœ")
"""