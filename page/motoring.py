import streamlit as st
import cv2
import mediapipe as mp
import pandas as pd
import os
from script import util
from script import fallpredict

def show():
    st.title("ğŸ›¡ï¸ ê°ì‹œ ëª¨ë“œ")
    st.write("ë‚™ìƒ ì—¬ë¶€ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤.")

    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils
    landmark_logs = []

    if 'camera' not in st.session_state:
        st.session_state.camera = None
    if 'history' not in st.session_state:
        st.session_state.history = []

    # í™”ë©´ ìƒë‹¨ êµ¬ì„±
    col1_top, col2_top, col3_top = st.columns([3.3, 3.4, 3.3])

    with col1_top:
        col1_box = st.empty()
        col1_box.info("aaaaaaaaa")

    with col2_top:
        col2_box = st.empty()
        col2_box.info("aaaaaaaaa")

    with col3_top:
        col3_box = st.empty()
        col3_box.info("aaaaaaaaa")

    st.markdown("---")
    # í™”ë©´ í•˜ë‹¨ êµ¬ì„±
    col1, col2 = st.columns([4, 6])

    with col2:
        st.markdown("### ğŸ“¥ ì‹¤ì‹œê°„ ë¶„ì„ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
        landmarks_box = st.empty()

    with col1:
        st.markdown("### ğŸ¥ ì›¹ìº ì„ ì´ìš©í•œ ì‹¤ì‹œê°„ ë¶„ì„")
        # ì¹´ë©”ë¼ ì‹œì‘/ì¢…ë£Œ ë²„íŠ¼ì„ ê°€ë¡œë¡œ ë‚˜ë€íˆ ë°°ì¹˜
        button_col1, button_col2, button_col3 = st.columns([2, 2, 2], gap="small")
        with button_col1:
            start = st.button("ì¹´ë©”ë¼ ì‹œì‘")
        with button_col2:
            stop = st.button("ì¹´ë©”ë¼ ì¢…ë£Œ")
        with button_col3:
            print("")
        frame_display = st.empty()  # ì˜ìƒ í‘œì‹œìš©

        frame_placeholder = st.empty()

        landmark_data = []  # ëˆ„ì  landmark ë°ì´í„° ì €ì¥

        if start:
            st.session_state.camera = cv2.VideoCapture(0)
            pose = mp_pose.Pose()
            last_print_time = 0
            analyzing = True

            while analyzing:
                ret, frame = st.session_state.camera.read()
                if not ret:
                    st.warning("ì¹´ë©”ë¼ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    break

                # BGR â†’ RGB ë³€í™˜
                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                # MediaPipe Pose ì²˜ë¦¬
                results = pose.process(image)

                # ëœë“œë§ˆí¬ê°€ ìˆìœ¼ë©´ ì²˜ë¦¬
                if results.pose_landmarks:
                    mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

                    lm = results.pose_landmarks.landmark
                    frame_landmarks = {
                        "timestamp": util.now_kst(),
                        "left_shoulder": (
                            round(lm[mp_pose.PoseLandmark.LEFT_SHOULDER].x, 2),
                            round(lm[mp_pose.PoseLandmark.LEFT_SHOULDER].y, 2),
                            round(lm[mp_pose.PoseLandmark.LEFT_SHOULDER].visibility, 2),
                            1 if round(lm[mp_pose.PoseLandmark.LEFT_SHOULDER].visibility, 2) >= 0.7 else 0
                        ),
                        "right_shoulder": (
                            round(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x, 2),
                            round(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y, 2),
                            round(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].visibility, 2),
                            1 if round(lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].visibility, 2) >= 0.7 else 0
                        ),
                        "left_knee": (
                            round(lm[mp_pose.PoseLandmark.LEFT_KNEE].x, 2),
                            round(lm[mp_pose.PoseLandmark.LEFT_KNEE].y, 2),
                            round(lm[mp_pose.PoseLandmark.LEFT_KNEE].visibility, 2),
                            1 if round(lm[mp_pose.PoseLandmark.LEFT_KNEE].visibility, 2) >= 0.7 else 0
                        ),
                        "right_knee": (
                            round(lm[mp_pose.PoseLandmark.RIGHT_KNEE].x, 2),
                            round(lm[mp_pose.PoseLandmark.RIGHT_KNEE].y, 2),
                            round(lm[mp_pose.PoseLandmark.RIGHT_KNEE].visibility, 2),
                            1 if round(lm[mp_pose.PoseLandmark.RIGHT_KNEE].visibility, 2) >= 0.7 else 0
                        ),
                    }
                    landmark_data.append(frame_landmarks)

                    # ëˆ„ì  ë¡œê·¸ 3ê°œ í‘œì‹œ
                    log_text = f"""
                    â± {frame_landmarks['timestamp']}  
        ğŸ¦´ ì™¼ìª½ ì–´ê¹¨: {frame_landmarks['left_shoulder']} ğŸ¦´ ì˜¤ë¥¸ìª½ ì–´ê¹¨: {frame_landmarks['right_shoulder']}  
        ğŸ¦µ ì™¼ìª½ ë¬´ë¦: {frame_landmarks['left_knee']} ğŸ¦µ ì˜¤ë¥¸ìª½ ë¬´ë¦: {frame_landmarks['right_knee']}  
                    """
                    landmark_logs.append(log_text)
                    landmarks_box.markdown("### ğŸ“ ëˆ„ì  ì¢Œí‘œ ë¡œê·¸(x,y,ì‹ ë¢°ë„,ì í•©ì—¬ë¶€)\n\n" + '\n---\n'.join(landmark_logs[-3:]), unsafe_allow_html=True)

                # í™”ë©´ì— ì¶œë ¥
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_placeholder.image(frame, channels="RGB")

                col1_box.success(f"{frame_landmarks['left_shoulder']}")
                col2_box.success(f"{frame_landmarks['right_shoulder']}")
                col3_box.success(f"{frame_landmarks['left_knee']}")

                # ë¶„ì„ ì¤‘ì§€ ë²„íŠ¼ì´ ëˆŒë¦¬ë©´
                if stop:
                    analyzing = False
                    break

            # ì¹´ë©”ë¼ í•´ì œ
            st.session_state.camera.release()
            st.session_state.camera = None