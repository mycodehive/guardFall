import streamlit as st
import numpy as np
import pandas as pd
import os, time, io
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
import joblib

def show():
    st.title("ğŸ§  ëª¨ë¸ ìƒì„±")
    st.write("ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.")

    displaytime = 1.5
    progress_box = st.empty()
    question_box = st.empty()
    answer_box = st.empty()

    csv_dir = os.path.abspath(os.path.join("user", "csv"))
    csv_files = [f for f in os.listdir(csv_dir) if f.endswith(".csv") and f != "merged_user_data.csv"]

    time.sleep(displaytime)
    progress_box.success("âœ”ï¸ íŒŒì¼ì„ ë³‘í•© ì¤‘ì…ë‹ˆë‹¤...")

    df_list = []
    for file in csv_files:
        file_path = os.path.join(csv_dir, file)
        df = pd.read_csv(file_path)
        df_list.append(df)
    file_name = "\n".join(csv_files)
    st.code(file_name)

    time.sleep(displaytime)
    merged_df = pd.concat(df_list, ignore_index=True)
    progress_box.success(f"âœ”ï¸ ì´ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ í•©ì³ì„œ í•˜ë‚˜ì˜ ë°ì´í„°ë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤.")

    time.sleep(displaytime)
    filtered_df = merged_df[merged_df["checkFall"] == 1]
    total_falls = filtered_df.shape[0]
    st.info(f"âœ”ï¸ ì „ì²´ ë°ì´í„° ì¤‘ ë‚™ìƒìœ¼ë¡œ íŒë³„ëœ ë°ì´í„°({total_falls}ê±´)ë§Œ ë³´ê¸° ì™„ë£Œ")
    st.dataframe(filtered_df)

    time.sleep(displaytime)
    csv_path = os.path.join(csv_dir, "merged_user_data.csv")
    merged_df.to_csv(csv_path, index=False)

    time.sleep(displaytime)
    progress_box.success("âœ”ï¸ CSV ë³‘í•© íŒŒì¼ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

    df = pd.read_csv(csv_path)
    #buffer = io.StringIO()
    #df.info(buf=buffer)
    #info_str = buffer.getvalue()
    #st.text(info_str)

    time.sleep(displaytime)
    progress_box.success("âœ”ï¸ [1] ì…ë ¥(X)ê³¼ íƒ€ê²Ÿ(y)ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.")
    X = df.drop(columns=['timestamp', 'checkFall'])
    y = df['checkFall']

    time.sleep(displaytime)
    progress_box.success("âœ”ï¸ [2] ìŠ¤ì¼€ì¼ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    time.sleep(displaytime)
    progress_box.success("âœ”ï¸ [3] í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )

    time.sleep(displaytime)
    progress_box.success("âœ”ï¸ [4] ëª¨ë¸ì„ ì •ì˜í•©ë‹ˆë‹¤.")
    model = Sequential([
        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
        Dropout(0.3),
        Dense(32, activation='relu'),
        Dropout(0.3),
        Dense(1, activation='sigmoid')
    ])

    time.sleep(displaytime)
    progress_box.success("âœ”ï¸ [5] ëª¨ë¸ì„ ì»´íŒŒì¼í•©ë‹ˆë‹¤.")
    model.compile(
        optimizer=Adam(learning_rate=0.001),
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    time.sleep(displaytime)
    progress_box.success("âœ”ï¸ [6] EarlyStoppingì„ ì ìš©í•©ë‹ˆë‹¤.")
    early_stopping = EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True
    )

    time.sleep(displaytime)
    progress_box.warning("âœ”ï¸ [7] ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦½ë‹ˆë‹¤. ì¡°ê¸ˆë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.")
    history = model.fit(
        X_train, y_train,
        validation_data=(X_test, y_test),
        epochs=100,
        batch_size=32,
        callbacks=[early_stopping],
        verbose=1
    )

    model_dir = os.path.abspath(os.path.join("user", "model"))
    os.makedirs(model_dir, exist_ok=True)

    time.sleep(displaytime)
    progress_box.success("âœ”ï¸ [8] ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤.")
    model_save_path = os.path.join(model_dir, 'fall_model.keras')
    model.save(model_save_path)

    time.sleep(displaytime)
    progress_box.success("âœ”ï¸ [9] ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.")
    scaler_save_path = os.path.join(model_dir, 'scaler.pkl')
    joblib.dump(scaler, scaler_save_path)

    time.sleep(displaytime)
    progress_box.info(f"ğŸ‰ ëª¨ë¸ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! '{model_dir}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")