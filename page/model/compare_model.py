import streamlit as st
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import load_model
from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score
import os

def show(auto_run):
    if auto_run:
        st.title("ëª¨ë¸ì„ ë¹„êµí•©ë‹ˆë‹¤")
        st.write("ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ 3ê°€ì§€ í•™ìŠµ ëª¨ë¸ì„ ë¹„êµí•©ë‹ˆë‹¤.")

        csv_dir = os.path.abspath(os.path.join("user", "csv"))
        file_path = os.path.join(csv_dir, "merged_user_data.csv")
        df = pd.read_csv(file_path)

        X = df.drop(columns=["timestamp", "checkFall"]).values
        y_true = df["checkFall"].values

        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        model_dir = os.path.abspath(os.path.join("user", "model"))
        model_paths = {
            "Dense Model": os.path.join(model_dir, "fall_model_denseModel.keras"),
            "LSTM Model": os.path.join(model_dir, "fall_model_lstmModel.keras"),
            "Ensemble Model": os.path.join(model_dir, "fall_model_ensembleModel.keras"),
        }

        results = []

        for model_name, path in model_paths.items():
            model = load_model(path)

            if model_name == "Ensemble Model":
                X_input = [X_scaled, X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))]
            elif len(model.input_shape) == 3:
                X_input = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))
            else:
                X_input = X_scaled

            y_pred = model.predict(X_input)
            y_pred_label = (y_pred > 0.5).astype(int).flatten()

            accuracy = accuracy_score(y_true, y_pred_label)
            recall = recall_score(y_true, y_pred_label, average='macro')
            f1 = f1_score(y_true, y_pred_label, average='macro')
            precision = precision_score(y_true, y_pred_label, average='macro')
            consistency = np.std(y_pred)

            results.append({
                "ëª¨ë¸ëª…": model_name,
                "ì •í™•ë„(Accuracy)": f"{accuracy * 100:.2f}%",
                "ì¬í˜„ìœ¨(Recall)": f"{recall * 100:.2f}%",
                "ì •ë°€ë„(Precision)": f"{precision * 100:.2f}%",
                "F1-score": f"{f1 * 100:.2f}%",
                "ì¶”ë¡  ì¼ê´€ì„±(í‘œì¤€í¸ì°¨)": f"{consistency:.4f}"
            })

        results_df = pd.DataFrame(results)
        results_df["ì •í™•ë„(%)"] = results_df["ì •í™•ë„(Accuracy)"].str.replace('%', '').astype(float)
        results_df["ì¬í˜„ìœ¨(%)"] = results_df["ì¬í˜„ìœ¨(Recall)"].str.replace('%', '').astype(float)
        results_df["ì •ë°€ë„(%)"] = results_df["ì •ë°€ë„(Precision)"].str.replace('%', '').astype(float)
        results_df["F1(%)"] = results_df["F1-score"].str.replace('%', '').astype(float)
        results_df["í‘œì¤€í¸ì°¨"] = results_df["ì¶”ë¡  ì¼ê´€ì„±(í‘œì¤€í¸ì°¨)"].astype(float)

        st.table(results_df[["ëª¨ë¸ëª…", "ì •í™•ë„(Accuracy)", "ì¬í˜„ìœ¨(Recall)", "ì •ë°€ë„(Precision)", "F1-score", "ì¶”ë¡  ì¼ê´€ì„±(í‘œì¤€í¸ì°¨)"]])

        # ì¢…í•© ì •ë ¬
        accuracy_sorted = results_df.sort_values(by="ì •í™•ë„(%)", ascending=False)["ëª¨ë¸ëª…"].tolist()
        recall_sorted = results_df.sort_values(by="ì¬í˜„ìœ¨(%)", ascending=False)["ëª¨ë¸ëª…"].tolist()
        precision_sorted = results_df.sort_values(by="ì •ë°€ë„(%)", ascending=False)["ëª¨ë¸ëª…"].tolist()
        f1_sorted = results_df.sort_values(by="F1(%)", ascending=False)["ëª¨ë¸ëª…"].tolist()
        stability_sorted = results_df.sort_values(by="í‘œì¤€í¸ì°¨", ascending=True)["ëª¨ë¸ëª…"].tolist()

        best_acc = results_df["ì •í™•ë„(%)"].max()
        acc_best_models = results_df[results_df["ì •í™•ë„(%)"] == best_acc]["ëª¨ë¸ëª…"].tolist()

        best_recall = results_df["ì¬í˜„ìœ¨(%)"].max()
        recall_best_models = results_df[results_df["ì¬í˜„ìœ¨(%)"] == best_recall]["ëª¨ë¸ëª…"].tolist()

        best_f1 = results_df["F1(%)"].max()
        f1_best_models = results_df[results_df["F1(%)"] == best_f1]["ëª¨ë¸ëª…"].tolist()

        min_std = results_df["í‘œì¤€í¸ì°¨"].min()
        std_best_models = results_df[results_df["í‘œì¤€í¸ì°¨"] == min_std]["ëª¨ë¸ëª…"].tolist()

        st.markdown(f"""
        ## ğŸ“Š ëª¨ë¸ ì¢…í•© ë¶„ì„

        - **ì •í™•ë„**: {' / '.join(acc_best_models)} ëª¨ë¸ì´ {best_acc:.2f}%ë¡œ ê°€ì¥ ìš°ìˆ˜í•©ë‹ˆë‹¤.
        - **ì¬í˜„ìœ¨(Recall)**: {' / '.join(recall_best_models)} ëª¨ë¸ì´ {best_recall:.2f}%ë¡œ ë‚™ìƒì„ ê°€ì¥ ì˜ ê°ì§€í•©ë‹ˆë‹¤.
        - **F1-score**: {' / '.join(f1_best_models)} ëª¨ë¸ì´ {best_f1:.2f}%ë¡œ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ê· í˜•ì´ ê°€ì¥ ì¢‹ìŠµë‹ˆë‹¤.
        - **ì¶”ë¡  ì¼ê´€ì„±(í‘œì¤€í¸ì°¨)**: {' / '.join(std_best_models)} ëª¨ë¸ì´ {min_std:.4f}ë¡œ ê°€ì¥ ì•ˆì •ì ì…ë‹ˆë‹¤.
        """)

        st.markdown(f"""
        | í‰ê°€ í•­ëª©       | ê¸°ì¤€ ìˆœìœ„                                | ì„¤ëª… |
|----------------|-------------------------------------------|------|
| ğŸ” ì •í™•ë„ (Accuracy)     | {' > '.join(accuracy_sorted)}           | ì „ì²´ ì˜ˆì¸¡ ì¤‘ ë§ì¶˜ ë¹„ìœ¨ |
| ğŸ“ˆ ì¬í˜„ìœ¨ (Recall)       | {' > '.join(recall_sorted)}           | ì‹¤ì œ ë‚™ìƒ ì¤‘ ê°ì§€í•œ ë¹„ìœ¨ (ë¯¼ê°ë„) |
| ğŸ¯ ì •ë°€ë„ (Precision)   | {' > '.join(precision_sorted)}           | ê°ì§€ëœ ë‚™ìƒ ì¤‘ ì‹¤ì œ ë‚™ìƒì¼ í™•ë¥  |
| âš–ï¸ F1-score            | {' > '.join(f1_sorted)}          | ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ê· í˜• |
| ğŸ“‰ ì¶”ë¡  ì¼ê´€ì„± (í‘œì¤€í¸ì°¨) | {' > '.join(stability_sorted)}          | ì˜ˆì¸¡ì˜ í”ë“¤ë¦¼ ì—†ì´ ì•ˆì •ì ì¸ ì •ë„ |
        """, unsafe_allow_html=True)